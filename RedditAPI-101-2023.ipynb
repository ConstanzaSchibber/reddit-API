{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial: Retrieving Posts and Comments from Reddit using the Reddit API\n",
    "\n",
    "The Reddit Data API launched in 2008.\n",
    "\n",
    "There are constraints to how much data we can retrieve through the API because maintaining the API is expensive and those using the API cause server traffic. Some of the limitations are:\n",
    "\n",
    "- You can make a max of 60 requests per minute\n",
    "- You can request up to 100 items (e.g. posts) per request\n",
    "- It is easier to collect current data and plan to collect into the future than retrieving historical data with the reddit API.\n",
    "\n",
    "For more information, check out the API documentation here: https://www.reddit.com/dev/api/\n",
    "\n",
    "## Step 1: Create a Reddit Developer Account \n",
    "\n",
    "After creating an account in reddit and logging in, go here: https://www.reddit.com/prefs/apps\n",
    "\n",
    "Go to the end of the webpage where it says `Developed Applications` and click `Create another app`.  You will see a form which you can fill in as follows:\n",
    "\n",
    "-  `name`, choose any name for your app; mine is called MyBot for lack of originality.\n",
    "- Three Options: The default is `web app` but for pulling reddit data you need to change it `script` which allows us to use the API for personal reasons. The other options available allow you to develop apps, bots, etc.\n",
    "- `description`, briefly explain what you are going to use the API for.\n",
    "- `about url`, leave empty.\n",
    "- `redirect url`, if you do not have one, enter http://localhost:8080\n",
    "\n",
    "## Step 2: Get Credentials to Access API \n",
    "\n",
    "Now you are registered! We need to get the credentials to access the API. If you go again here https://www.reddit.com/prefs/apps, while logged into your account, you will find the application you created in the previous step under `developed applications`. \n",
    "\n",
    "You will see the following information:\n",
    "\n",
    "[SCREEN SHOT]\n",
    "\n",
    "The API requires OAuth 2.0 which stands for *Open Authorization*. It is an authorization framework that, in this case, allows reddit to grant access to third-parties (developers or users retrieving data for personal use) to their protected resources (e.g. reddit posts). To go through the authentication process, you will need the following:\n",
    "\n",
    "- Reddit username\n",
    "- Reddit password\n",
    "- Client secret\n",
    "- Client ID\n",
    "\n",
    "To make the information secure, I saved the information in a JSON file that looks like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "javascript"
    }
   },
   "outputs": [],
   "source": [
    "{\n",
    "    \"USERNAME_REDDIT\": \"YourUsername\",\n",
    "    \"PASSWORD_REDDIT\": \"YourPassword\",\n",
    "    \"CLIENT_SECRET\": \"YourSecret\",\n",
    "    \"CLIENT_ID\": \"YourClient\"\n",
    "}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " After creating the file with the credentials, you should include it in a `.gitignore` file. \n",
    "\n",
    "We are now ready to move to Python! Below are all of the libraries I will use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all libraries needed for all steps\n",
    "import json\n",
    "import requests\n",
    "import pandas as pd\n",
    "import datetime"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now load the credentials from the JSON file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read json file which is saved in the same folder\n",
    "with open(\".json\") as json_file:\n",
    "    credentials = json.load(json_file)\n",
    "\n",
    "# read username & password & secret & ID saved in hidden file\n",
    "USERNAME = credentials['USERNAME_REDDIT']\n",
    "PASSWORD = credentials['PASSWORD_REDDIT']\n",
    "CLIENT_SECRET = credentials['CLIENT_SECRET']\n",
    "CLIENT_ID = credentials['CLIENT_ID']\n",
    "\n",
    "# uncomment below if you want to check that the information is correct\n",
    "# print(USERNAME, PASSWORD, CLIENT_SECRET, CLIENT_ID)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Step 3: Request Authorization to API and get Oauth Token\n",
    "\n",
    "We are now ready to request an **access token** to access the reddit API. The token will provide access for 2 hours, after which you will need to request a new token.\n",
    "\n",
    "To request the authorization token, we use `requests.post` with inputs `auth` (which includes the client ID and secret),`data` (which includes the reddit username and password), and `headers` (which provides information about the client -me- requesting the resource). We also include the reddit link that provides the access token. Reddit API provides the token in JSON format along with other information. I save the token in an object called `TOKEN` for later use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# information for log-in authorization\n",
    "auth = requests.auth.HTTPBasicAuth(CLIENT_ID, CLIENT_SECRET)\n",
    "\n",
    "data = {'grant_type': 'password', 'username': USERNAME, 'password': PASSWORD}\n",
    "\n",
    "headers = {'User-Agent': 'myBot/1.0'}\n",
    "\n",
    "# submit our request for an OAuth token\n",
    "res = requests.post('https://www.reddit.com/api/v1/access_token',\n",
    "                    auth=auth, data=data, headers=headers)\n",
    "\n",
    "# Uncomment below to see the access token and other information\n",
    "# # print(res.json())\n",
    "\n",
    "# retrieve access token\n",
    "TOKEN = res.json()['access_token']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Request Reddit Posts and Save Them in a DataFrame\n",
    "\n",
    "Now that we have the authorization token, we can get some data from the reddit API! \n",
    "\n",
    "To make requests we use `requests.get`. The data will be provided in a JSON format.\n",
    "\n",
    "We can filter the data modifying the link:\n",
    "\n",
    "https://oauth.reddit.com/r/{subreddit}/{type}.json?t={time}\n",
    "\n",
    "where,\n",
    "\n",
    "- Subreddit is the name of the subreddit you want to pull data from.\n",
    "\n",
    "- Type is what I call the way reddit allows users to sort/look for posts:\n",
    "    - 'hot'\n",
    "    - 'top'\n",
    "    - 'new'\n",
    "    - 'controversial'\n",
    "    - 'rising'\n",
    "    - 'random'\n",
    "    - 'best'\n",
    "\n",
    "- Time refers to day, week, month, or year. \n",
    "\n",
    "we can specify the subreddit, the number of posts to pull (max allowed is 100), whether/how to sort it, search posts by keywords, among others\n",
    "\n",
    "Using the filters we could get, for instance, the top 100 posts in a particular subreddit in the last year. Let's try it out! \n",
    "\n",
    "In the example below, I specify `my_headers` and `my_params` and later, pull 100 posts from today (default) that are 'hot' from the data science subreddit. After, I pull the top 100 hot posts from the same subreddit for the past year. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add authorization to headers\n",
    "my_headers = {**headers, **{'Authorization': f\"bearer {TOKEN}\"}}\n",
    "\n",
    "# add sorting by date and get 100\n",
    "my_params = {'sort': 'date', 'limit': 100}\n",
    "\n",
    "reddit_hot = requests.get(\"https://oauth.reddit.com/r/datascience/hot.json\",\n",
    "                   headers=my_headers, params=my_params)\n",
    "\n",
    "\n",
    "reddit_hot_year = requests.get(\"https://oauth.reddit.com/r/datascience/top.json?t=year\",\n",
    "                   headers=headers, params=my_params)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each post, we can get the following information:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['approved_at_utc', 'subreddit', 'selftext', 'author_fullname', 'saved', 'mod_reason_title', 'gilded', 'clicked', 'title', 'link_flair_richtext', 'subreddit_name_prefixed', 'hidden', 'pwls', 'link_flair_css_class', 'downs', 'thumbnail_height', 'top_awarded_type', 'hide_score', 'name', 'quarantine', 'link_flair_text_color', 'upvote_ratio', 'author_flair_background_color', 'subreddit_type', 'ups', 'total_awards_received', 'media_embed', 'thumbnail_width', 'author_flair_template_id', 'is_original_content', 'user_reports', 'secure_media', 'is_reddit_media_domain', 'is_meta', 'category', 'secure_media_embed', 'link_flair_text', 'can_mod_post', 'score', 'approved_by', 'is_created_from_ads_ui', 'author_premium', 'thumbnail', 'edited', 'author_flair_css_class', 'author_flair_richtext', 'gildings', 'content_categories', 'is_self', 'mod_note', 'created', 'link_flair_type', 'wls', 'removed_by_category', 'banned_by', 'author_flair_type', 'domain', 'allow_live_comments', 'selftext_html', 'likes', 'suggested_sort', 'banned_at_utc', 'view_count', 'archived', 'no_follow', 'is_crosspostable', 'pinned', 'over_18', 'all_awardings', 'awarders', 'media_only', 'can_gild', 'spoiler', 'locked', 'author_flair_text', 'treatment_tags', 'visited', 'removed_by', 'num_reports', 'distinguished', 'subreddit_id', 'author_is_blocked', 'mod_reason_by', 'removal_reason', 'link_flair_background_color', 'id', 'is_robot_indexable', 'report_reasons', 'author', 'discussion_type', 'num_comments', 'send_replies', 'whitelist_status', 'contest_mode', 'mod_reports', 'author_patreon_flair', 'author_flair_text_color', 'permalink', 'parent_whitelist_status', 'stickied', 'url', 'subreddit_subscribers', 'created_utc', 'num_crossposts', 'media', 'is_video'])\n"
     ]
    }
   ],
   "source": [
    "# variables for each post\n",
    "print(reddit_hot.json()['data']['children'][0]['data'].keys())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also filter posts with key words:\n",
    "\n",
    "https://oauth.reddit.com/r/{subreddit}/search.json?q={key_words}&restrict_sr=on\n",
    "\n",
    "where:\n",
    "- subreddit is the subreddit we want to search (note: like above, you have to add `restrict_sr=on` so that the search is restricted to the subreddit)\n",
    "- key_words are the key words you want to use for your search; white spaces are replaced by `_`.\n",
    "\n",
    "In the example below I pull the last 100 posts with key words ChatGPT."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "reddit_gpt = requests.get(\"https://oauth.reddit.com/r/datascience/search.json?q=ChatGPT&restrict_sr=on\",\n",
    "                            headers=headers, params=my_params)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On a side note, the date in which a post is created is called `created` and are unix timestamps -- number of seconds since January 1, 1970. It is trivial to convert in Python using the `datetime` library. For instance, the first post, the unix timestamp is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1695009704.0\n"
     ]
    }
   ],
   "source": [
    "created_post0 = reddit_hot.json()['data']['children'][0]['data'].get('created')\n",
    "print(created_post0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Converted to UTC below, it yields 24 of April 2023 at 04:01:26."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.datetime(2023, 9, 18, 4, 1, 44)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datetime.datetime.utcfromtimestamp(created_post0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To create a data frame with the posts, I select a number of attributes and do the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()  # initialize dataframe\n",
    "\n",
    "# loop through each post retrieved from GET request\n",
    "for post in reddit_hot.json()['data']['children']:\n",
    "    # append relevant data to dataframe\n",
    "    df = df.append({\n",
    "        'subreddit': post['data']['subreddit'],\n",
    "        'id': post['data']['id'],\n",
    "        'title': post['data']['title'],\n",
    "        'selftext': post['data']['selftext'],\n",
    "        'upvote_ratio': post['data']['upvote_ratio'],\n",
    "        'ups': post['data']['ups'],\n",
    "        'downs': post['data']['downs'],\n",
    "        'score': post['data']['score'],\n",
    "        'num_comments': post['data']['num_comments'],\n",
    "        'view_count': post['data']['view_count'],\n",
    "        'total_awards': post['data']['total_awards_received'],\n",
    "        'created': post['data']['created']\n",
    "    }, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subreddit</th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>selftext</th>\n",
       "      <th>upvote_ratio</th>\n",
       "      <th>ups</th>\n",
       "      <th>downs</th>\n",
       "      <th>score</th>\n",
       "      <th>num_comments</th>\n",
       "      <th>view_count</th>\n",
       "      <th>total_awards</th>\n",
       "      <th>created</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>datascience</td>\n",
       "      <td>16ll6ro</td>\n",
       "      <td>Weekly Entering &amp;amp; Transitioning - Thread 1...</td>\n",
       "      <td>\\n\\nWelcome to this week's entering &amp;amp; tra...</td>\n",
       "      <td>0.90</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>None</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.695010e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>datascience</td>\n",
       "      <td>16r1881</td>\n",
       "      <td>Poor statistical/Linear Algebra foundation</td>\n",
       "      <td>Often you hear people saying that understandin...</td>\n",
       "      <td>0.84</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>None</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.695571e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>datascience</td>\n",
       "      <td>16qtywk</td>\n",
       "      <td>For people in the industry, how do you explain...</td>\n",
       "      <td>I'll be having a job interview in a few days a...</td>\n",
       "      <td>0.96</td>\n",
       "      <td>70.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>None</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.695550e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>datascience</td>\n",
       "      <td>16r5v0j</td>\n",
       "      <td>What do data scientists do anyway?</td>\n",
       "      <td>I have been working in a data science Consulti...</td>\n",
       "      <td>0.80</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>None</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.695582e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>datascience</td>\n",
       "      <td>16qxfo0</td>\n",
       "      <td>Did academics prepare you for your role, or fo...</td>\n",
       "      <td>I browse through post often and general have l...</td>\n",
       "      <td>0.84</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>None</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.695561e+09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     subreddit       id                                              title  \\\n",
       "0  datascience  16ll6ro  Weekly Entering &amp; Transitioning - Thread 1...   \n",
       "1  datascience  16r1881         Poor statistical/Linear Algebra foundation   \n",
       "2  datascience  16qtywk  For people in the industry, how do you explain...   \n",
       "3  datascience  16r5v0j                 What do data scientists do anyway?   \n",
       "4  datascience  16qxfo0  Did academics prepare you for your role, or fo...   \n",
       "\n",
       "                                            selftext  upvote_ratio   ups  \\\n",
       "0   \\n\\nWelcome to this week's entering &amp; tra...          0.90   7.0   \n",
       "1  Often you hear people saying that understandin...          0.84  26.0   \n",
       "2  I'll be having a job interview in a few days a...          0.96  70.0   \n",
       "3  I have been working in a data science Consulti...          0.80  12.0   \n",
       "4  I browse through post often and general have l...          0.84  11.0   \n",
       "\n",
       "   downs  score  num_comments view_count  total_awards       created  \n",
       "0    0.0    7.0         106.0       None           0.0  1.695010e+09  \n",
       "1    0.0   26.0          22.0       None           0.0  1.695571e+09  \n",
       "2    0.0   70.0          27.0       None           0.0  1.695550e+09  \n",
       "3    0.0   12.0          21.0       None           0.0  1.695582e+09  \n",
       "4    0.0   11.0          11.0       None           0.0  1.695561e+09  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(101, 12)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Retrieving Comments from a Post"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Moving to the comments, in order to retrieve them, we need an ID for a specific post (in the case below, post 12x2df1, which is [this](https://www.reddit.com/r/datascience/comments/12x2df1/weekly_entering_transitioning_thread_24_apr_2023/) thread.)\n",
    "\n",
    "The comments appear as a tree. For simplicity, I collect only the *parent* comments only and save them in a DataFrame below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'kind': 't3', 'data': {'approved_at_utc': None, 'subreddit': 'datascience', 'selftext': \" \\n\\nWelcome to this week's entering &amp; transitioning thread! This thread is for any questions about getting started, studying, or transitioning into the data science field. Topics include:\\n\\n* Learning resources (e.g. books, tutorials, videos)\\n* Traditional education (e.g. schools, degrees, electives)\\n* Alternative education (e.g. online courses, bootcamps)\\n* Job search questions (e.g. resumes, applying, career prospects)\\n* Elementary questions (e.g. where to start, what next)\\n\\nWhile you wait for answers from the community, check out the [FAQ](https://www.reddit.com/r/datascience/wiki/frequently-asked-questions) and Resources pages on our wiki. You can also search for answers in [past weekly threads](https://www.reddit.com/r/datascience/search?q=weekly%20thread&amp;restrict_sr=1&amp;sort=new).\", 'user_reports': [], 'saved': False, 'mod_reason_title': None, 'gilded': 0, 'clicked': False, 'title': 'Weekly Entering &amp; Transitioning - Thread 24 Apr, 2023 - 01 May, 2023', 'link_flair_richtext': [], 'subreddit_name_prefixed': 'r/datascience', 'hidden': False, 'pwls': 6, 'link_flair_css_class': None, 'downs': 0, 'thumbnail_height': None, 'top_awarded_type': None, 'parent_whitelist_status': 'all_ads', 'hide_score': False, 'name': 't3_12x2df1', 'quarantine': False, 'link_flair_text_color': 'dark', 'upvote_ratio': 1.0, 'author_flair_background_color': None, 'subreddit_type': 'public', 'ups': 17, 'total_awards_received': 0, 'media_embed': {}, 'thumbnail_width': None, 'author_flair_template_id': None, 'is_original_content': False, 'author_fullname': 't2_6l4z3', 'secure_media': None, 'is_reddit_media_domain': False, 'is_meta': False, 'category': None, 'secure_media_embed': {}, 'link_flair_text': None, 'can_mod_post': False, 'score': 17, 'approved_by': None, 'is_created_from_ads_ui': False, 'author_premium': True, 'thumbnail': 'self', 'edited': False, 'author_flair_css_class': None, 'author_flair_richtext': [], 'gildings': {}, 'content_categories': None, 'is_self': True, 'mod_note': None, 'created': 1682308886.0, 'link_flair_type': 'text', 'wls': 6, 'removed_by_category': None, 'banned_by': None, 'author_flair_type': 'text', 'domain': 'self.datascience', 'allow_live_comments': False, 'selftext_html': '&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Welcome to this week&amp;#39;s entering &amp;amp; transitioning thread! This thread is for any questions about getting started, studying, or transitioning into the data science field. Topics include:&lt;/p&gt;\\n\\n&lt;ul&gt;\\n&lt;li&gt;Learning resources (e.g. books, tutorials, videos)&lt;/li&gt;\\n&lt;li&gt;Traditional education (e.g. schools, degrees, electives)&lt;/li&gt;\\n&lt;li&gt;Alternative education (e.g. online courses, bootcamps)&lt;/li&gt;\\n&lt;li&gt;Job search questions (e.g. resumes, applying, career prospects)&lt;/li&gt;\\n&lt;li&gt;Elementary questions (e.g. where to start, what next)&lt;/li&gt;\\n&lt;/ul&gt;\\n\\n&lt;p&gt;While you wait for answers from the community, check out the &lt;a href=\"https://www.reddit.com/r/datascience/wiki/frequently-asked-questions\"&gt;FAQ&lt;/a&gt; and Resources pages on our wiki. You can also search for answers in &lt;a href=\"https://www.reddit.com/r/datascience/search?q=weekly%20thread&amp;amp;restrict_sr=1&amp;amp;sort=new\"&gt;past weekly threads&lt;/a&gt;.&lt;/p&gt;\\n&lt;/div&gt;&lt;!-- SC_ON --&gt;', 'likes': None, 'suggested_sort': 'new', 'banned_at_utc': None, 'view_count': None, 'archived': False, 'no_follow': False, 'is_crosspostable': True, 'pinned': False, 'over_18': False, 'all_awardings': [], 'awarders': [], 'media_only': False, 'can_gild': False, 'spoiler': False, 'locked': False, 'author_flair_text': None, 'treatment_tags': [], 'visited': False, 'removed_by': None, 'num_reports': None, 'distinguished': None, 'subreddit_id': 't5_2sptq', 'author_is_blocked': False, 'mod_reason_by': None, 'removal_reason': None, 'link_flair_background_color': '', 'id': '12x2df1', 'is_robot_indexable': True, 'num_duplicates': 0, 'report_reasons': None, 'author': 'AutoModerator', 'discussion_type': None, 'num_comments': 125, 'send_replies': False, 'media': None, 'contest_mode': False, 'author_patreon_flair': False, 'author_flair_text_color': None, 'permalink': '/r/datascience/comments/12x2df1/weekly_entering_transitioning_thread_24_apr_2023/', 'whitelist_status': 'all_ads', 'stickied': False, 'url': 'https://www.reddit.com/r/datascience/comments/12x2df1/weekly_entering_transitioning_thread_24_apr_2023/', 'subreddit_subscribers': 1059428, 'created_utc': 1682308886.0, 'num_crossposts': 0, 'mod_reports': [], 'is_video': False}}\n",
      "{'subreddit_id': 't5_2sptq', 'approved_at_utc': None, 'author_is_blocked': False, 'comment_type': None, 'awarders': [], 'mod_reason_by': None, 'banned_by': None, 'author_flair_type': 'text', 'total_awards_received': 0, 'subreddit': 'datascience', 'author_flair_template_id': None, 'likes': None, 'replies': {'kind': 'Listing', 'data': {'after': None, 'dist': None, 'modhash': None, 'geo_filter': '', 'children': [{'kind': 't1', 'data': {'subreddit_id': 't5_2sptq', 'approved_at_utc': None, 'author_is_blocked': False, 'comment_type': None, 'awarders': [], 'mod_reason_by': None, 'banned_by': None, 'author_flair_type': 'text', 'total_awards_received': 0, 'subreddit': 'datascience', 'author_flair_template_id': None, 'likes': None, 'replies': '', 'user_reports': [], 'saved': False, 'id': 'jhm1zwt', 'banned_at_utc': None, 'mod_reason_title': None, 'gilded': 0, 'archived': False, 'collapsed_reason_code': None, 'no_follow': True, 'author': 'data_story_teller', 'can_mod_post': False, 'created_utc': 1682395665.0, 'send_replies': True, 'parent_id': 't1_jhkplu9', 'score': 3, 'author_fullname': 't2_vm02lsz7', 'removal_reason': None, 'approved_by': None, 'mod_note': None, 'all_awardings': [], 'body': '“I’ve already started interviews with another company, but you’re my top choice. Is it possible to wrap up interviews with your company by next week or soon after?”', 'edited': False, 'top_awarded_type': None, 'author_flair_css_class': None, 'name': 't1_jhm1zwt', 'is_submitter': False, 'downs': 0, 'author_flair_richtext': [], 'author_patreon_flair': False, 'body_html': '&lt;div class=\"md\"&gt;&lt;p&gt;“I’ve already started interviews with another company, but you’re my top choice. Is it possible to wrap up interviews with your company by next week or soon after?”&lt;/p&gt;\\n&lt;/div&gt;', 'gildings': {}, 'collapsed_reason': None, 'distinguished': None, 'associated_award': None, 'stickied': False, 'author_premium': False, 'can_gild': False, 'link_id': 't3_12x2df1', 'unrepliable_reason': None, 'author_flair_text_color': None, 'score_hidden': False, 'permalink': '/r/datascience/comments/12x2df1/weekly_entering_transitioning_thread_24_apr_2023/jhm1zwt/', 'subreddit_type': 'public', 'locked': False, 'report_reasons': None, 'created': 1682395665.0, 'author_flair_text': None, 'treatment_tags': [], 'collapsed': False, 'subreddit_name_prefixed': 'r/datascience', 'controversiality': 0, 'depth': 1, 'author_flair_background_color': None, 'collapsed_because_crowd_control': None, 'mod_reports': [], 'num_reports': None, 'ups': 3}}], 'before': None}}, 'user_reports': [], 'saved': False, 'id': 'jhkplu9', 'banned_at_utc': None, 'mod_reason_title': None, 'gilded': 0, 'archived': False, 'collapsed_reason_code': None, 'no_follow': False, 'author': 'junejiehuang', 'can_mod_post': False, 'created_utc': 1682373068.0, 'send_replies': True, 'parent_id': 't3_12x2df1', 'score': 4, 'author_fullname': 't2_17dvcp', 'approved_by': None, 'mod_note': None, 'all_awardings': [], 'collapsed': False, 'body': \"I'm having a final interview next week for an entry level ds role, which fingers crossed I get. I'm also leaving for a month long vacation in three weeks. Question is, I just got a first round from another company, can I ask them to speed up the process because of my situation? And if I ask to speed it up, how should I explain my situation to them?\", 'edited': False, 'top_awarded_type': None, 'author_flair_css_class': None, 'name': 't1_jhkplu9', 'is_submitter': False, 'downs': 0, 'author_flair_richtext': [], 'author_patreon_flair': False, 'body_html': '&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m having a final interview next week for an entry level ds role, which fingers crossed I get. I&amp;#39;m also leaving for a month long vacation in three weeks. Question is, I just got a first round from another company, can I ask them to speed up the process because of my situation? And if I ask to speed it up, how should I explain my situation to them?&lt;/p&gt;\\n&lt;/div&gt;', 'removal_reason': None, 'collapsed_reason': None, 'distinguished': None, 'associated_award': None, 'stickied': False, 'author_premium': False, 'can_gild': False, 'gildings': {}, 'unrepliable_reason': None, 'author_flair_text_color': None, 'score_hidden': False, 'permalink': '/r/datascience/comments/12x2df1/weekly_entering_transitioning_thread_24_apr_2023/jhkplu9/', 'subreddit_type': 'public', 'locked': False, 'report_reasons': None, 'created': 1682373068.0, 'author_flair_text': None, 'treatment_tags': [], 'link_id': 't3_12x2df1', 'subreddit_name_prefixed': 'r/datascience', 'controversiality': 0, 'depth': 0, 'author_flair_background_color': None, 'collapsed_because_crowd_control': None, 'mod_reports': [], 'num_reports': None, 'ups': 4}\n"
     ]
    }
   ],
   "source": [
    "reddit_comments = requests.get(\"https://oauth.reddit.com/r/datascience/comments/12x2df1.json?threded=false\",\n",
    "                   headers=my_headers, params=my_params)\n",
    "print(reddit_comments.json()[0]['data']['children'][0])\n",
    "print(reddit_comments.json()[1]['data']['children'][1]['data'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_comments = pd.DataFrame()  # initialize dataframe\n",
    "\n",
    "# loop through each post retrieved from GET request\n",
    "for i in range(0, len(reddit_comments.json()[1]['data']['children'])):\n",
    "    # append relevant data to dataframe\n",
    "    df_comments = df_comments.append({\n",
    "        'subreddit': reddit_comments.json()[1]['data']['children'][i]['data']['subreddit'],\n",
    "        'id': reddit_comments.json()[1]['data']['children'][i]['data']['id'],\n",
    "        'body': reddit_comments.json()[1]['data']['children'][i]['data']['body'],\n",
    "        'ups': reddit_comments.json()[1]['data']['children'][i]['data']['ups'],\n",
    "        'downs': reddit_comments.json()[1]['data']['children'][i]['data']['downs'],\n",
    "        'score': reddit_comments.json()[1]['data']['children'][i]['data']['score'],\n",
    "        'total_awards': reddit_comments.json()[1]['data']['children'][i]['data']['total_awards_received'],\n",
    "        'created': reddit_comments.json()[1]['data']['children'][i]['data']['created_utc'],\n",
    "        'author': reddit_comments.json()[1]['data']['children'][i]['data']['author']\n",
    "        \n",
    "    }, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(36, 10)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_comments.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subreddit</th>\n",
       "      <th>id</th>\n",
       "      <th>body</th>\n",
       "      <th>ups</th>\n",
       "      <th>downs</th>\n",
       "      <th>score</th>\n",
       "      <th>total_awards</th>\n",
       "      <th>created</th>\n",
       "      <th>author</th>\n",
       "      <th>num_replies</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>datascience</td>\n",
       "      <td>jhjhfkf</td>\n",
       "      <td>Hi all,\\n\\nI have got question about moving fr...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.682356e+09</td>\n",
       "      <td>Quest_to_peace</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>datascience</td>\n",
       "      <td>jhkplu9</td>\n",
       "      <td>I'm having a final interview next week for an ...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.682373e+09</td>\n",
       "      <td>junejiehuang</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>datascience</td>\n",
       "      <td>jhytaqq</td>\n",
       "      <td>[deleted]</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.682628e+09</td>\n",
       "      <td>[deleted]</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>datascience</td>\n",
       "      <td>jhhrzhw</td>\n",
       "      <td>Hey is it possible to go into data science wit...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.682322e+09</td>\n",
       "      <td>Far-Pizza9567bNana</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>datascience</td>\n",
       "      <td>jhihp20</td>\n",
       "      <td>This is a cry for help, if you can give me som...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.682341e+09</td>\n",
       "      <td>moon3dot14</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     subreddit       id                                               body  \\\n",
       "0  datascience  jhjhfkf  Hi all,\\n\\nI have got question about moving fr...   \n",
       "1  datascience  jhkplu9  I'm having a final interview next week for an ...   \n",
       "2  datascience  jhytaqq                                          [deleted]   \n",
       "3  datascience  jhhrzhw  Hey is it possible to go into data science wit...   \n",
       "4  datascience  jhihp20  This is a cry for help, if you can give me som...   \n",
       "\n",
       "   ups  downs  score  total_awards       created              author  \\\n",
       "0  5.0    0.0    5.0           0.0  1.682356e+09      Quest_to_peace   \n",
       "1  4.0    0.0    4.0           0.0  1.682373e+09        junejiehuang   \n",
       "2  5.0    0.0    5.0           0.0  1.682628e+09           [deleted]   \n",
       "3  3.0    0.0    3.0           0.0  1.682322e+09  Far-Pizza9567bNana   \n",
       "4  3.0    0.0    3.0           0.0  1.682341e+09          moon3dot14   \n",
       "\n",
       "   num_replies  \n",
       "0          2.0  \n",
       "1          2.0  \n",
       "2          2.0  \n",
       "3          2.0  \n",
       "4          2.0  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_comments.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
