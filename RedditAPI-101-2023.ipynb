{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial: Retrieving Posts and Comments from Reddit using the Reddit API\n",
    "\n",
    "The Reddit Data API launched in 2008.\n",
    "\n",
    "There are constraints to how much data we can retrieve through the API because maintaining the API is expensive and those using the API cause server traffic. Some of the limitations are:\n",
    "\n",
    "- You can make a max of 60 requests per minute\n",
    "- You can request up to 100 items (e.g. posts) per request\n",
    "- It is easier to collect current data and plan to collect into the future than retrieving historical data with the reddit API.\n",
    "\n",
    "For more information, check out the API documentation here: https://www.reddit.com/dev/api/\n",
    "\n",
    "## Step 1: Create a Reddit Developer Account \n",
    "\n",
    "After creating an account in reddit and logging in, go here: https://www.reddit.com/prefs/apps\n",
    "\n",
    "Go to the end of the webpage where it says `Developed Applications` and click `Create another app`.  You will see a form which you can fill in as follows:\n",
    "\n",
    "-  `name`, choose any name for your app; mine is called MyBot for lack of originality.\n",
    "- Three Options: The default is `web app` but for pulling reddit data you need to change it `script` which allows us to use the API for personal reasons. The other options available allow you to develop apps, bots, etc.\n",
    "- `description`, briefly explain what you are going to use the API for.\n",
    "- `about url`, leave empty.\n",
    "- `redirect url`, if you do not have one, enter http://localhost:8080\n",
    "\n",
    "## Step 2: Get Credentials to Access API \n",
    "\n",
    "Now you are registered! We need to get the credentials to access the API. If you go again here https://www.reddit.com/prefs/apps, while logged into your account, you will find the application you created in the previous step under `developed applications`. \n",
    "\n",
    "You will see the following information:\n",
    "\n",
    "[SCREEN SHOT]\n",
    "\n",
    "The API requires OAuth 2.0 which stands for *Open Authorization*. It is an authorization framework that, in this case, allows reddit to grant access to third-parties (developers or users retrieving data for personal use) to their protected resources (e.g. reddit posts). To go through the authentication process, you will need the following:\n",
    "\n",
    "- Reddit username\n",
    "- Reddit password\n",
    "- Client secret\n",
    "- Client ID\n",
    "\n",
    "To make the information secure, I saved the information in a JSON file that looks like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "javascript"
    }
   },
   "outputs": [],
   "source": [
    "{\n",
    "    \"USERNAME_REDDIT\": \"YourUsername\",\n",
    "    \"PASSWORD_REDDIT\": \"YourPassword\",\n",
    "    \"CLIENT_SECRET\": \"YourSecret\",\n",
    "    \"CLIENT_ID\": \"YourClient\"\n",
    "}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " After creating the file with the credentials, you should include it in a `.gitignore` file. \n",
    "\n",
    "We are now ready to move to Python! Below are all of the libraries I will use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all libraries needed for all steps\n",
    "import json\n",
    "import requests\n",
    "import pandas as pd\n",
    "import datetime"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now load the credentials from the JSON file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read json file which is saved in the same folder\n",
    "with open(\".json\") as json_file:\n",
    "    credentials = json.load(json_file)\n",
    "\n",
    "# read username & password & secret & ID saved in hidden file\n",
    "USERNAME = credentials['USERNAME_REDDIT']\n",
    "PASSWORD = credentials['PASSWORD_REDDIT']\n",
    "CLIENT_SECRET = credentials['CLIENT_SECRET']\n",
    "CLIENT_ID = credentials['CLIENT_ID']\n",
    "\n",
    "# uncomment below if you want to check that the information is correct\n",
    "# print(USERNAME, PASSWORD, CLIENT_SECRET, CLIENT_ID)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Step 3: Request Authorization to API and get Oauth Token\n",
    "\n",
    "We are now ready to request an **access token** to access the reddit API. The token will provide access for 2 hours, after which you will need to request a new token.\n",
    "\n",
    "To request the authorization token, we use `requests.post` with inputs `auth` (which includes the client ID and secret),`data` (which includes the reddit username and password), and `headers` (which provides information about the client -me- requesting the resource). We also include the reddit link that provides the access token. Reddit API provides the token in JSON format along with other information. I save the token in an object called `TOKEN` for later use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# information for log-in authorization\n",
    "auth = requests.auth.HTTPBasicAuth(CLIENT_ID, CLIENT_SECRET)\n",
    "\n",
    "data = {'grant_type': 'password', 'username': USERNAME, 'password': PASSWORD}\n",
    "\n",
    "headers = {'User-Agent': 'myBot/1.0'}\n",
    "\n",
    "# submit our request for an OAuth token\n",
    "res = requests.post('https://www.reddit.com/api/v1/access_token',\n",
    "                    auth=auth, data=data, headers=headers)\n",
    "\n",
    "# Uncomment below to see the access token and other information\n",
    "# # print(res.json())\n",
    "\n",
    "# retrieve access token\n",
    "TOKEN = res.json()['access_token']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Request Reddit Posts and Save Them in a DataFrame\n",
    "\n",
    "Now that we have the authorization token, we can get some data from the reddit API! \n",
    "\n",
    "To make requests we use `requests.get`. The data will be provided in a JSON format.\n",
    "\n",
    "We can filter the data modifying the link:\n",
    "\n",
    "https://oauth.reddit.com/r/{subreddit}/{type}.json?t={time}\n",
    "\n",
    "where,\n",
    "\n",
    "- Subreddit is the name of the subreddit you want to pull data from.\n",
    "\n",
    "- Type is what I call the way reddit allows users to sort/look for posts:\n",
    "    - 'hot'\n",
    "    - 'top'\n",
    "    - 'new'\n",
    "    - 'controversial'\n",
    "    - 'rising'\n",
    "    - 'random'\n",
    "    - 'best'\n",
    "\n",
    "- Time refers to day, week, month, or year. \n",
    "\n",
    "we can specify the subreddit, the number of posts to pull (max allowed is 100), whether/how to sort it, search posts by keywords, among others\n",
    "\n",
    "Using the filters we could get, for instance, the top 100 posts in a particular subreddit in the last year. Let's try it out! \n",
    "\n",
    "In the example below, I specify `my_headers` and `my_params` and later, pull 100 posts from today (default) that are 'hot' from the data science subreddit. After, I pull the top 100 hot posts from the same subreddit for the past year. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add authorization to headers\n",
    "my_headers = {**headers, **{'Authorization': f\"bearer {TOKEN}\"}}\n",
    "\n",
    "# add sorting by date and get 100\n",
    "my_params = {'sort': 'date', 'limit': 100}\n",
    "\n",
    "reddit_hot = requests.get(\"https://oauth.reddit.com/r/datascience/hot.json\",\n",
    "                   headers=my_headers, params=my_params)\n",
    "\n",
    "\n",
    "reddit_hot_year = requests.get(\"https://oauth.reddit.com/r/datascience/top.json?t=year\",\n",
    "                   headers=headers, params=my_params)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each post, we can get the following information:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['approved_at_utc', 'subreddit', 'selftext', 'author_fullname', 'saved', 'mod_reason_title', 'gilded', 'clicked', 'title', 'link_flair_richtext', 'subreddit_name_prefixed', 'hidden', 'pwls', 'link_flair_css_class', 'downs', 'thumbnail_height', 'top_awarded_type', 'hide_score', 'name', 'quarantine', 'link_flair_text_color', 'upvote_ratio', 'author_flair_background_color', 'subreddit_type', 'ups', 'total_awards_received', 'media_embed', 'thumbnail_width', 'author_flair_template_id', 'is_original_content', 'user_reports', 'secure_media', 'is_reddit_media_domain', 'is_meta', 'category', 'secure_media_embed', 'link_flair_text', 'can_mod_post', 'score', 'approved_by', 'is_created_from_ads_ui', 'author_premium', 'thumbnail', 'edited', 'author_flair_css_class', 'author_flair_richtext', 'gildings', 'content_categories', 'is_self', 'mod_note', 'created', 'link_flair_type', 'wls', 'removed_by_category', 'banned_by', 'author_flair_type', 'domain', 'allow_live_comments', 'selftext_html', 'likes', 'suggested_sort', 'banned_at_utc', 'view_count', 'archived', 'no_follow', 'is_crosspostable', 'pinned', 'over_18', 'all_awardings', 'awarders', 'media_only', 'can_gild', 'spoiler', 'locked', 'author_flair_text', 'treatment_tags', 'visited', 'removed_by', 'num_reports', 'distinguished', 'subreddit_id', 'author_is_blocked', 'mod_reason_by', 'removal_reason', 'link_flair_background_color', 'id', 'is_robot_indexable', 'report_reasons', 'author', 'discussion_type', 'num_comments', 'send_replies', 'whitelist_status', 'contest_mode', 'mod_reports', 'author_patreon_flair', 'author_flair_text_color', 'permalink', 'parent_whitelist_status', 'stickied', 'url', 'subreddit_subscribers', 'created_utc', 'num_crossposts', 'media', 'is_video'])\n"
     ]
    }
   ],
   "source": [
    "# variables for each post\n",
    "print(reddit_hot.json()['data']['children'][0]['data'].keys())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also filter posts with key words:\n",
    "\n",
    "https://oauth.reddit.com/r/{subreddit}/search.json?q={key_words}&restrict_sr=on\n",
    "\n",
    "where:\n",
    "- subreddit is the subreddit we want to search (note: like above, you have to add `restrict_sr=on` so that the search is restricted to the subreddit)\n",
    "- key_words are the key words you want to use for your search; white spaces are replaced by `_`.\n",
    "\n",
    "In the example below I pull the last 100 posts with key words ChatGPT."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "reddit_gpt = requests.get(\"https://oauth.reddit.com/r/datascience/search.json?q=ChatGPT&restrict_sr=on\",\n",
    "                            headers=headers, params=my_params)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On a side note, the date in which a post is created is called `created` and are unix timestamps -- number of seconds since January 1, 1970. It is trivial to convert in Python using the `datetime` library. For instance, the first post, the unix timestamp is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1695009704.0\n"
     ]
    }
   ],
   "source": [
    "created_post0 = reddit_hot.json()['data']['children'][0]['data'].get('created')\n",
    "print(created_post0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Converted to UTC below, it yields 24 of April 2023 at 04:01:26."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.datetime(2023, 9, 18, 4, 1, 44)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datetime.datetime.utcfromtimestamp(created_post0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To create a data frame with the posts, I select a number of attributes and do the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()  # initialize dataframe\n",
    "\n",
    "# loop through each post retrieved from GET request\n",
    "for post in reddit_hot.json()['data']['children']:\n",
    "    # append relevant data to dataframe\n",
    "    df = df.append({\n",
    "        'subreddit': post['data']['subreddit'],\n",
    "        'id': post['data']['id'],\n",
    "        'title': post['data']['title'],\n",
    "        'selftext': post['data']['selftext'],\n",
    "        'upvote_ratio': post['data']['upvote_ratio'],\n",
    "        'ups': post['data']['ups'],\n",
    "        'downs': post['data']['downs'],\n",
    "        'score': post['data']['score'],\n",
    "        'num_comments': post['data']['num_comments'],\n",
    "        'view_count': post['data']['view_count'],\n",
    "        'total_awards': post['data']['total_awards_received'],\n",
    "        'created': post['data']['created']\n",
    "    }, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subreddit</th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>selftext</th>\n",
       "      <th>upvote_ratio</th>\n",
       "      <th>ups</th>\n",
       "      <th>downs</th>\n",
       "      <th>score</th>\n",
       "      <th>num_comments</th>\n",
       "      <th>view_count</th>\n",
       "      <th>total_awards</th>\n",
       "      <th>created</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>datascience</td>\n",
       "      <td>16ll6ro</td>\n",
       "      <td>Weekly Entering &amp;amp; Transitioning - Thread 1...</td>\n",
       "      <td>\\n\\nWelcome to this week's entering &amp;amp; tra...</td>\n",
       "      <td>0.90</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>None</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.695010e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>datascience</td>\n",
       "      <td>16r1881</td>\n",
       "      <td>Poor statistical/Linear Algebra foundation</td>\n",
       "      <td>Often you hear people saying that understandin...</td>\n",
       "      <td>0.84</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>None</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.695571e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>datascience</td>\n",
       "      <td>16qtywk</td>\n",
       "      <td>For people in the industry, how do you explain...</td>\n",
       "      <td>I'll be having a job interview in a few days a...</td>\n",
       "      <td>0.96</td>\n",
       "      <td>70.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>None</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.695550e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>datascience</td>\n",
       "      <td>16r5v0j</td>\n",
       "      <td>What do data scientists do anyway?</td>\n",
       "      <td>I have been working in a data science Consulti...</td>\n",
       "      <td>0.80</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>None</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.695582e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>datascience</td>\n",
       "      <td>16qxfo0</td>\n",
       "      <td>Did academics prepare you for your role, or fo...</td>\n",
       "      <td>I browse through post often and general have l...</td>\n",
       "      <td>0.84</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>None</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.695561e+09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     subreddit       id                                              title  \\\n",
       "0  datascience  16ll6ro  Weekly Entering &amp; Transitioning - Thread 1...   \n",
       "1  datascience  16r1881         Poor statistical/Linear Algebra foundation   \n",
       "2  datascience  16qtywk  For people in the industry, how do you explain...   \n",
       "3  datascience  16r5v0j                 What do data scientists do anyway?   \n",
       "4  datascience  16qxfo0  Did academics prepare you for your role, or fo...   \n",
       "\n",
       "                                            selftext  upvote_ratio   ups  \\\n",
       "0   \\n\\nWelcome to this week's entering &amp; tra...          0.90   7.0   \n",
       "1  Often you hear people saying that understandin...          0.84  26.0   \n",
       "2  I'll be having a job interview in a few days a...          0.96  70.0   \n",
       "3  I have been working in a data science Consulti...          0.80  12.0   \n",
       "4  I browse through post often and general have l...          0.84  11.0   \n",
       "\n",
       "   downs  score  num_comments view_count  total_awards       created  \n",
       "0    0.0    7.0         106.0       None           0.0  1.695010e+09  \n",
       "1    0.0   26.0          22.0       None           0.0  1.695571e+09  \n",
       "2    0.0   70.0          27.0       None           0.0  1.695550e+09  \n",
       "3    0.0   12.0          21.0       None           0.0  1.695582e+09  \n",
       "4    0.0   11.0          11.0       None           0.0  1.695561e+09  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(101, 12)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Retrieving Comments from a Post"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Moving to the comments, in order to retrieve them, we need an ID for a specific post (in the case below, post 12x2df1, which is [this](https://www.reddit.com/r/datascience/comments/12x2df1/weekly_entering_transitioning_thread_24_apr_2023/) thread.)\n",
    "\n",
    "The comments appear as a tree. For simplicity, I collect only the *parent* comments only and save them in a DataFrame below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'kind': 't3', 'data': {'approved_at_utc': None, 'subreddit': 'datascience', 'selftext': \" \\n\\nWelcome to this week's entering &amp; transitioning thread! This thread is for any questions about getting started, studying, or transitioning into the data science field. Topics include:\\n\\n* Learning resources (e.g. books, tutorials, videos)\\n* Traditional education (e.g. schools, degrees, electives)\\n* Alternative education (e.g. online courses, bootcamps)\\n* Job search questions (e.g. resumes, applying, career prospects)\\n* Elementary questions (e.g. where to start, what next)\\n\\nWhile you wait for answers from the community, check out the [FAQ](https://www.reddit.com/r/datascience/wiki/frequently-asked-questions) and Resources pages on our wiki. You can also search for answers in [past weekly threads](https://www.reddit.com/r/datascience/search?q=weekly%20thread&amp;restrict_sr=1&amp;sort=new).\", 'user_reports': [], 'saved': False, 'mod_reason_title': None, 'gilded': 0, 'clicked': False, 'title': 'Weekly Entering &amp; Transitioning - Thread 24 Apr, 2023 - 01 May, 2023', 'link_flair_richtext': [], 'subreddit_name_prefixed': 'r/datascience', 'hidden': False, 'pwls': 6, 'link_flair_css_class': None, 'downs': 0, 'thumbnail_height': None, 'top_awarded_type': None, 'parent_whitelist_status': 'all_ads', 'hide_score': False, 'name': 't3_12x2df1', 'quarantine': False, 'link_flair_text_color': 'dark', 'upvote_ratio': 0.95, 'author_flair_background_color': None, 'subreddit_type': 'public', 'ups': 15, 'total_awards_received': 0, 'media_embed': {}, 'thumbnail_width': None, 'author_flair_template_id': None, 'is_original_content': False, 'author_fullname': 't2_6l4z3', 'secure_media': None, 'is_reddit_media_domain': False, 'is_meta': False, 'category': None, 'secure_media_embed': {}, 'link_flair_text': None, 'can_mod_post': False, 'score': 15, 'approved_by': None, 'is_created_from_ads_ui': False, 'author_premium': True, 'thumbnail': 'self', 'edited': False, 'author_flair_css_class': None, 'author_flair_richtext': [], 'gildings': {}, 'content_categories': None, 'is_self': True, 'mod_note': None, 'created': 1682308886.0, 'link_flair_type': 'text', 'wls': 6, 'removed_by_category': None, 'banned_by': None, 'author_flair_type': 'text', 'domain': 'self.datascience', 'allow_live_comments': False, 'selftext_html': '&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Welcome to this week&amp;#39;s entering &amp;amp; transitioning thread! This thread is for any questions about getting started, studying, or transitioning into the data science field. Topics include:&lt;/p&gt;\\n\\n&lt;ul&gt;\\n&lt;li&gt;Learning resources (e.g. books, tutorials, videos)&lt;/li&gt;\\n&lt;li&gt;Traditional education (e.g. schools, degrees, electives)&lt;/li&gt;\\n&lt;li&gt;Alternative education (e.g. online courses, bootcamps)&lt;/li&gt;\\n&lt;li&gt;Job search questions (e.g. resumes, applying, career prospects)&lt;/li&gt;\\n&lt;li&gt;Elementary questions (e.g. where to start, what next)&lt;/li&gt;\\n&lt;/ul&gt;\\n\\n&lt;p&gt;While you wait for answers from the community, check out the &lt;a href=\"https://www.reddit.com/r/datascience/wiki/frequently-asked-questions\"&gt;FAQ&lt;/a&gt; and Resources pages on our wiki. You can also search for answers in &lt;a href=\"https://www.reddit.com/r/datascience/search?q=weekly%20thread&amp;amp;restrict_sr=1&amp;amp;sort=new\"&gt;past weekly threads&lt;/a&gt;.&lt;/p&gt;\\n&lt;/div&gt;&lt;!-- SC_ON --&gt;', 'likes': None, 'suggested_sort': 'new', 'banned_at_utc': None, 'view_count': None, 'archived': False, 'no_follow': False, 'is_crosspostable': True, 'pinned': False, 'over_18': False, 'all_awardings': [], 'awarders': [], 'media_only': False, 'can_gild': False, 'spoiler': False, 'locked': False, 'author_flair_text': None, 'treatment_tags': [], 'visited': False, 'removed_by': None, 'num_reports': None, 'distinguished': None, 'subreddit_id': 't5_2sptq', 'author_is_blocked': False, 'mod_reason_by': None, 'removal_reason': None, 'link_flair_background_color': '', 'id': '12x2df1', 'is_robot_indexable': True, 'num_duplicates': 0, 'report_reasons': None, 'author': 'AutoModerator', 'discussion_type': None, 'num_comments': 125, 'send_replies': False, 'media': None, 'contest_mode': False, 'author_patreon_flair': False, 'author_flair_text_color': None, 'permalink': '/r/datascience/comments/12x2df1/weekly_entering_transitioning_thread_24_apr_2023/', 'whitelist_status': 'all_ads', 'stickied': False, 'url': 'https://www.reddit.com/r/datascience/comments/12x2df1/weekly_entering_transitioning_thread_24_apr_2023/', 'subreddit_subscribers': 1059476, 'created_utc': 1682308886.0, 'num_crossposts': 0, 'mod_reports': [], 'is_video': False}}\n",
      "{'subreddit_id': 't5_2sptq', 'approved_at_utc': None, 'author_is_blocked': False, 'comment_type': None, 'awarders': [], 'mod_reason_by': None, 'banned_by': None, 'author_flair_type': 'text', 'total_awards_received': 0, 'subreddit': 'datascience', 'author_flair_template_id': None, 'likes': None, 'replies': {'kind': 'Listing', 'data': {'after': None, 'dist': None, 'modhash': None, 'geo_filter': '', 'children': [{'kind': 't1', 'data': {'subreddit_id': 't5_2sptq', 'approved_at_utc': None, 'author_is_blocked': False, 'comment_type': None, 'awarders': [], 'mod_reason_by': None, 'banned_by': None, 'author_flair_type': 'text', 'total_awards_received': 0, 'subreddit': 'datascience', 'author_flair_template_id': None, 'likes': None, 'replies': '', 'user_reports': [], 'saved': False, 'id': 'jhm1zwt', 'banned_at_utc': None, 'mod_reason_title': None, 'gilded': 0, 'archived': False, 'collapsed_reason_code': None, 'no_follow': True, 'author': 'data_story_teller', 'can_mod_post': False, 'created_utc': 1682395665.0, 'send_replies': True, 'parent_id': 't1_jhkplu9', 'score': 3, 'author_fullname': 't2_vm02lsz7', 'removal_reason': None, 'approved_by': None, 'mod_note': None, 'all_awardings': [], 'body': '“I’ve already started interviews with another company, but you’re my top choice. Is it possible to wrap up interviews with your company by next week or soon after?”', 'edited': False, 'top_awarded_type': None, 'author_flair_css_class': None, 'name': 't1_jhm1zwt', 'is_submitter': False, 'downs': 0, 'author_flair_richtext': [], 'author_patreon_flair': False, 'body_html': '&lt;div class=\"md\"&gt;&lt;p&gt;“I’ve already started interviews with another company, but you’re my top choice. Is it possible to wrap up interviews with your company by next week or soon after?”&lt;/p&gt;\\n&lt;/div&gt;', 'gildings': {}, 'collapsed_reason': None, 'distinguished': None, 'associated_award': None, 'stickied': False, 'author_premium': False, 'can_gild': False, 'link_id': 't3_12x2df1', 'unrepliable_reason': None, 'author_flair_text_color': None, 'score_hidden': False, 'permalink': '/r/datascience/comments/12x2df1/weekly_entering_transitioning_thread_24_apr_2023/jhm1zwt/', 'subreddit_type': 'public', 'locked': False, 'report_reasons': None, 'created': 1682395665.0, 'author_flair_text': None, 'treatment_tags': [], 'collapsed': False, 'subreddit_name_prefixed': 'r/datascience', 'controversiality': 0, 'depth': 1, 'author_flair_background_color': None, 'collapsed_because_crowd_control': None, 'mod_reports': [], 'num_reports': None, 'ups': 3}}], 'before': None}}, 'user_reports': [], 'saved': False, 'id': 'jhkplu9', 'banned_at_utc': None, 'mod_reason_title': None, 'gilded': 0, 'archived': False, 'collapsed_reason_code': None, 'no_follow': False, 'author': 'junejiehuang', 'can_mod_post': False, 'created_utc': 1682373068.0, 'send_replies': True, 'parent_id': 't3_12x2df1', 'score': 3, 'author_fullname': 't2_17dvcp', 'approved_by': None, 'mod_note': None, 'all_awardings': [], 'collapsed': False, 'body': \"I'm having a final interview next week for an entry level ds role, which fingers crossed I get. I'm also leaving for a month long vacation in three weeks. Question is, I just got a first round from another company, can I ask them to speed up the process because of my situation? And if I ask to speed it up, how should I explain my situation to them?\", 'edited': False, 'top_awarded_type': None, 'author_flair_css_class': None, 'name': 't1_jhkplu9', 'is_submitter': False, 'downs': 0, 'author_flair_richtext': [], 'author_patreon_flair': False, 'body_html': '&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m having a final interview next week for an entry level ds role, which fingers crossed I get. I&amp;#39;m also leaving for a month long vacation in three weeks. Question is, I just got a first round from another company, can I ask them to speed up the process because of my situation? And if I ask to speed it up, how should I explain my situation to them?&lt;/p&gt;\\n&lt;/div&gt;', 'removal_reason': None, 'collapsed_reason': None, 'distinguished': None, 'associated_award': None, 'stickied': False, 'author_premium': False, 'can_gild': False, 'gildings': {}, 'unrepliable_reason': None, 'author_flair_text_color': None, 'score_hidden': False, 'permalink': '/r/datascience/comments/12x2df1/weekly_entering_transitioning_thread_24_apr_2023/jhkplu9/', 'subreddit_type': 'public', 'locked': False, 'report_reasons': None, 'created': 1682373068.0, 'author_flair_text': None, 'treatment_tags': [], 'link_id': 't3_12x2df1', 'subreddit_name_prefixed': 'r/datascience', 'controversiality': 0, 'depth': 0, 'author_flair_background_color': None, 'collapsed_because_crowd_control': None, 'mod_reports': [], 'num_reports': None, 'ups': 3}\n"
     ]
    }
   ],
   "source": [
    "reddit_comments = requests.get(\"https://oauth.reddit.com/r/datascience/comments/12x2df1.json?threded=false\",\n",
    "                   headers=my_headers, params=my_params)\n",
    "print(reddit_comments.json()[0]['data']['children'][0])\n",
    "print(reddit_comments.json()[1]['data']['children'][1]['data'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_comments = pd.DataFrame()  # initialize dataframe\n",
    "\n",
    "# loop through each post retrieved from GET request\n",
    "for i in range(0, len(reddit_comments.json()[1]['data']['children'])):\n",
    "    # append relevant data to dataframe\n",
    "    df_comments = df_comments.append({\n",
    "        'subreddit': reddit_comments.json()[1]['data']['children'][i]['data']['subreddit'],\n",
    "        'id': reddit_comments.json()[1]['data']['children'][i]['data']['id'],\n",
    "        'body': reddit_comments.json()[1]['data']['children'][i]['data']['body'],\n",
    "        'ups': reddit_comments.json()[1]['data']['children'][i]['data']['ups'],\n",
    "        'downs': reddit_comments.json()[1]['data']['children'][i]['data']['downs'],\n",
    "        'score': reddit_comments.json()[1]['data']['children'][i]['data']['score'],\n",
    "        'total_awards': reddit_comments.json()[1]['data']['children'][i]['data']['total_awards_received'],\n",
    "        'created': reddit_comments.json()[1]['data']['children'][i]['data']['created_utc'],\n",
    "        'author': reddit_comments.json()[1]['data']['children'][i]['data']['author']\n",
    "        \n",
    "    }, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(36, 9)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_comments.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subreddit</th>\n",
       "      <th>id</th>\n",
       "      <th>body</th>\n",
       "      <th>ups</th>\n",
       "      <th>downs</th>\n",
       "      <th>score</th>\n",
       "      <th>total_awards</th>\n",
       "      <th>created</th>\n",
       "      <th>author</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>datascience</td>\n",
       "      <td>jhjhfkf</td>\n",
       "      <td>Hi all,\\n\\nI have got question about moving fr...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.682356e+09</td>\n",
       "      <td>Quest_to_peace</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>datascience</td>\n",
       "      <td>jhkplu9</td>\n",
       "      <td>I'm having a final interview next week for an ...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.682373e+09</td>\n",
       "      <td>junejiehuang</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>datascience</td>\n",
       "      <td>jhytaqq</td>\n",
       "      <td>[deleted]</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.682628e+09</td>\n",
       "      <td>[deleted]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>datascience</td>\n",
       "      <td>jhhrzhw</td>\n",
       "      <td>Hey is it possible to go into data science wit...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.682322e+09</td>\n",
       "      <td>Far-Pizza9567bNana</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>datascience</td>\n",
       "      <td>jhihp20</td>\n",
       "      <td>This is a cry for help, if you can give me som...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.682341e+09</td>\n",
       "      <td>moon3dot14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     subreddit       id                                               body  \\\n",
       "0  datascience  jhjhfkf  Hi all,\\n\\nI have got question about moving fr...   \n",
       "1  datascience  jhkplu9  I'm having a final interview next week for an ...   \n",
       "2  datascience  jhytaqq                                          [deleted]   \n",
       "3  datascience  jhhrzhw  Hey is it possible to go into data science wit...   \n",
       "4  datascience  jhihp20  This is a cry for help, if you can give me som...   \n",
       "\n",
       "   ups  downs  score  total_awards       created              author  \n",
       "0  5.0    0.0    5.0           0.0  1.682356e+09      Quest_to_peace  \n",
       "1  3.0    0.0    3.0           0.0  1.682373e+09        junejiehuang  \n",
       "2  4.0    0.0    4.0           0.0  1.682628e+09           [deleted]  \n",
       "3  3.0    0.0    3.0           0.0  1.682322e+09  Far-Pizza9567bNana  \n",
       "4  3.0    0.0    3.0           0.0  1.682341e+09          moon3dot14  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_comments.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subreddit</th>\n",
       "      <th>id</th>\n",
       "      <th>body</th>\n",
       "      <th>ups</th>\n",
       "      <th>downs</th>\n",
       "      <th>score</th>\n",
       "      <th>total_awards</th>\n",
       "      <th>created</th>\n",
       "      <th>author</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>datascience</td>\n",
       "      <td>jhjhfkf</td>\n",
       "      <td>Hi all,\\n\\nI have got question about moving fr...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.682356e+09</td>\n",
       "      <td>Quest_to_peace</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>datascience</td>\n",
       "      <td>jhkplu9</td>\n",
       "      <td>I'm having a final interview next week for an ...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.682373e+09</td>\n",
       "      <td>junejiehuang</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>datascience</td>\n",
       "      <td>jhytaqq</td>\n",
       "      <td>[deleted]</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.682628e+09</td>\n",
       "      <td>[deleted]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>datascience</td>\n",
       "      <td>jhhrzhw</td>\n",
       "      <td>Hey is it possible to go into data science wit...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.682322e+09</td>\n",
       "      <td>Far-Pizza9567bNana</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>datascience</td>\n",
       "      <td>jhihp20</td>\n",
       "      <td>This is a cry for help, if you can give me som...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.682341e+09</td>\n",
       "      <td>moon3dot14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>datascience</td>\n",
       "      <td>jhk6txp</td>\n",
       "      <td>[deleted]</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.682366e+09</td>\n",
       "      <td>[deleted]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>datascience</td>\n",
       "      <td>jhkec69</td>\n",
       "      <td>The good other options:\\n\\nI request you to pl...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.682369e+09</td>\n",
       "      <td>Due-D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>datascience</td>\n",
       "      <td>jhlp9am</td>\n",
       "      <td>I'm majoring in psychology/neuroscience, and I...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.682389e+09</td>\n",
       "      <td>pirscent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>datascience</td>\n",
       "      <td>jhm0gfh</td>\n",
       "      <td>MS Analytics in a very reputable college or MS...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.682395e+09</td>\n",
       "      <td>allicrawley</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>datascience</td>\n",
       "      <td>jhmmndp</td>\n",
       "      <td>Anybody have suggestions on alternative career...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.682411e+09</td>\n",
       "      <td>GGPiggie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>datascience</td>\n",
       "      <td>jhos6x2</td>\n",
       "      <td>Background: data science minor, non tech major...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.682449e+09</td>\n",
       "      <td>[deleted]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>datascience</td>\n",
       "      <td>jhovm1t</td>\n",
       "      <td>Hows the job market? Thinking of finding new o...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.682450e+09</td>\n",
       "      <td>SuchExplanation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>datascience</td>\n",
       "      <td>jhhkj9w</td>\n",
       "      <td>Hi,\\n\\nI've got a question about transitioning...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.682316e+09</td>\n",
       "      <td>dudaspl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>datascience</td>\n",
       "      <td>jhjfy8v</td>\n",
       "      <td>I got laid off recently and am looking for a d...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.682355e+09</td>\n",
       "      <td>clarielz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>datascience</td>\n",
       "      <td>jhkg7jx</td>\n",
       "      <td>How difficult would it be to get into DS role ...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.682369e+09</td>\n",
       "      <td>Legolas_i_am</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>datascience</td>\n",
       "      <td>jhl4mc6</td>\n",
       "      <td>Hi. I'm looking to get to know the field and a...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.682380e+09</td>\n",
       "      <td>gftmc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>datascience</td>\n",
       "      <td>jhoh3ks</td>\n",
       "      <td>[deleted]</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.682445e+09</td>\n",
       "      <td>[deleted]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>datascience</td>\n",
       "      <td>jhpa7l3</td>\n",
       "      <td>[deleted]</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.682456e+09</td>\n",
       "      <td>[deleted]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>datascience</td>\n",
       "      <td>jhpo527</td>\n",
       "      <td>Hey everyone!\\n\\nI got admitted to the Univers...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.682462e+09</td>\n",
       "      <td>mindstudio3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>datascience</td>\n",
       "      <td>jhr0aj6</td>\n",
       "      <td>Where should I look for internships? \\nI just ...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.682486e+09</td>\n",
       "      <td>AV-Arkie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>datascience</td>\n",
       "      <td>jhru0vf</td>\n",
       "      <td>Is your role stressful? And what is your exact...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.682509e+09</td>\n",
       "      <td>3A1B2C33C2B1A3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>datascience</td>\n",
       "      <td>jhyf16e</td>\n",
       "      <td>Looking for input on transitioning into a data...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.682622e+09</td>\n",
       "      <td>aggierogue3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>datascience</td>\n",
       "      <td>ji0ldvv</td>\n",
       "      <td>what are common red flags in a start up that I...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.682657e+09</td>\n",
       "      <td>takeaway_272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>datascience</td>\n",
       "      <td>ji775rg</td>\n",
       "      <td>I am taking some online courses and I want to ...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.682786e+09</td>\n",
       "      <td>Shiroelf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>datascience</td>\n",
       "      <td>jhl5t2t</td>\n",
       "      <td>If you had to recommend 3 books to get started...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.682381e+09</td>\n",
       "      <td>[deleted]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>datascience</td>\n",
       "      <td>jhoi70k</td>\n",
       "      <td>Hey Fam,\\n\\nSo I've decided to slightly change...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.682445e+09</td>\n",
       "      <td>crazysexycoolent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>datascience</td>\n",
       "      <td>jhhnb6n</td>\n",
       "      <td>Experience / advice working for a very small t...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.682318e+09</td>\n",
       "      <td>Shopcell</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>datascience</td>\n",
       "      <td>jhj8x3b</td>\n",
       "      <td>Hello,\\n\\nI am an international student starti...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.682352e+09</td>\n",
       "      <td>AutomaticMistake9791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>datascience</td>\n",
       "      <td>jhu29ze</td>\n",
       "      <td>Another question:\\n\\nHas anyone used Thinkful'...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.682542e+09</td>\n",
       "      <td>clarielz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>datascience</td>\n",
       "      <td>jhud4ke</td>\n",
       "      <td>Looking for any wisdom, advice, or encourageme...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.682547e+09</td>\n",
       "      <td>tvgrlds</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>datascience</td>\n",
       "      <td>jhuuhl0</td>\n",
       "      <td>Hey guys, looking for advice because honestly ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.682555e+09</td>\n",
       "      <td>Kooky_Assistant112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>datascience</td>\n",
       "      <td>jhv34xv</td>\n",
       "      <td>what’s your ideal interview process length? I ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.682558e+09</td>\n",
       "      <td>takeaway_272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>datascience</td>\n",
       "      <td>jhwd2uv</td>\n",
       "      <td>Where a non technical start from calculus or c...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.682587e+09</td>\n",
       "      <td>[deleted]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>datascience</td>\n",
       "      <td>jhy5l7h</td>\n",
       "      <td>I am in a Ph.D. program in CS within the field...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.682619e+09</td>\n",
       "      <td>Sunapr1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>datascience</td>\n",
       "      <td>ji2oyzu</td>\n",
       "      <td>[deleted]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.682700e+09</td>\n",
       "      <td>[deleted]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>datascience</td>\n",
       "      <td>ji9gpop</td>\n",
       "      <td>Hello everyone,\\n\\nJust discovered this reddit...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.682824e+09</td>\n",
       "      <td>sidewayssadface</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      subreddit       id                                               body  \\\n",
       "0   datascience  jhjhfkf  Hi all,\\n\\nI have got question about moving fr...   \n",
       "1   datascience  jhkplu9  I'm having a final interview next week for an ...   \n",
       "2   datascience  jhytaqq                                          [deleted]   \n",
       "3   datascience  jhhrzhw  Hey is it possible to go into data science wit...   \n",
       "4   datascience  jhihp20  This is a cry for help, if you can give me som...   \n",
       "5   datascience  jhk6txp                                          [deleted]   \n",
       "6   datascience  jhkec69  The good other options:\\n\\nI request you to pl...   \n",
       "7   datascience  jhlp9am  I'm majoring in psychology/neuroscience, and I...   \n",
       "8   datascience  jhm0gfh  MS Analytics in a very reputable college or MS...   \n",
       "9   datascience  jhmmndp  Anybody have suggestions on alternative career...   \n",
       "10  datascience  jhos6x2  Background: data science minor, non tech major...   \n",
       "11  datascience  jhovm1t  Hows the job market? Thinking of finding new o...   \n",
       "12  datascience  jhhkj9w  Hi,\\n\\nI've got a question about transitioning...   \n",
       "13  datascience  jhjfy8v  I got laid off recently and am looking for a d...   \n",
       "14  datascience  jhkg7jx  How difficult would it be to get into DS role ...   \n",
       "15  datascience  jhl4mc6  Hi. I'm looking to get to know the field and a...   \n",
       "16  datascience  jhoh3ks                                          [deleted]   \n",
       "17  datascience  jhpa7l3                                          [deleted]   \n",
       "18  datascience  jhpo527  Hey everyone!\\n\\nI got admitted to the Univers...   \n",
       "19  datascience  jhr0aj6  Where should I look for internships? \\nI just ...   \n",
       "20  datascience  jhru0vf  Is your role stressful? And what is your exact...   \n",
       "21  datascience  jhyf16e  Looking for input on transitioning into a data...   \n",
       "22  datascience  ji0ldvv  what are common red flags in a start up that I...   \n",
       "23  datascience  ji775rg  I am taking some online courses and I want to ...   \n",
       "24  datascience  jhl5t2t  If you had to recommend 3 books to get started...   \n",
       "25  datascience  jhoi70k  Hey Fam,\\n\\nSo I've decided to slightly change...   \n",
       "26  datascience  jhhnb6n  Experience / advice working for a very small t...   \n",
       "27  datascience  jhj8x3b  Hello,\\n\\nI am an international student starti...   \n",
       "28  datascience  jhu29ze  Another question:\\n\\nHas anyone used Thinkful'...   \n",
       "29  datascience  jhud4ke  Looking for any wisdom, advice, or encourageme...   \n",
       "30  datascience  jhuuhl0  Hey guys, looking for advice because honestly ...   \n",
       "31  datascience  jhv34xv  what’s your ideal interview process length? I ...   \n",
       "32  datascience  jhwd2uv  Where a non technical start from calculus or c...   \n",
       "33  datascience  jhy5l7h  I am in a Ph.D. program in CS within the field...   \n",
       "34  datascience  ji2oyzu                                          [deleted]   \n",
       "35  datascience  ji9gpop  Hello everyone,\\n\\nJust discovered this reddit...   \n",
       "\n",
       "    ups  downs  score  total_awards       created                author  \n",
       "0   5.0    0.0    5.0           0.0  1.682356e+09        Quest_to_peace  \n",
       "1   3.0    0.0    3.0           0.0  1.682373e+09          junejiehuang  \n",
       "2   4.0    0.0    4.0           0.0  1.682628e+09             [deleted]  \n",
       "3   3.0    0.0    3.0           0.0  1.682322e+09    Far-Pizza9567bNana  \n",
       "4   3.0    0.0    3.0           0.0  1.682341e+09            moon3dot14  \n",
       "5   3.0    0.0    3.0           0.0  1.682366e+09             [deleted]  \n",
       "6   3.0    0.0    3.0           0.0  1.682369e+09                 Due-D  \n",
       "7   3.0    0.0    3.0           0.0  1.682389e+09              pirscent  \n",
       "8   3.0    0.0    3.0           0.0  1.682395e+09           allicrawley  \n",
       "9   3.0    0.0    3.0           0.0  1.682411e+09              GGPiggie  \n",
       "10  3.0    0.0    3.0           0.0  1.682449e+09             [deleted]  \n",
       "11  3.0    0.0    3.0           0.0  1.682450e+09       SuchExplanation  \n",
       "12  2.0    0.0    2.0           0.0  1.682316e+09               dudaspl  \n",
       "13  2.0    0.0    2.0           0.0  1.682355e+09              clarielz  \n",
       "14  2.0    0.0    2.0           0.0  1.682369e+09          Legolas_i_am  \n",
       "15  2.0    0.0    2.0           0.0  1.682380e+09                 gftmc  \n",
       "16  2.0    0.0    2.0           0.0  1.682445e+09             [deleted]  \n",
       "17  2.0    0.0    2.0           0.0  1.682456e+09             [deleted]  \n",
       "18  2.0    0.0    2.0           0.0  1.682462e+09           mindstudio3  \n",
       "19  2.0    0.0    2.0           0.0  1.682486e+09              AV-Arkie  \n",
       "20  2.0    0.0    2.0           0.0  1.682509e+09        3A1B2C33C2B1A3  \n",
       "21  2.0    0.0    2.0           0.0  1.682622e+09           aggierogue3  \n",
       "22  2.0    0.0    2.0           0.0  1.682657e+09          takeaway_272  \n",
       "23  2.0    0.0    2.0           0.0  1.682786e+09              Shiroelf  \n",
       "24  1.0    0.0    1.0           0.0  1.682381e+09             [deleted]  \n",
       "25  1.0    0.0    1.0           0.0  1.682445e+09      crazysexycoolent  \n",
       "26  1.0    0.0    1.0           0.0  1.682318e+09              Shopcell  \n",
       "27  1.0    0.0    1.0           0.0  1.682352e+09  AutomaticMistake9791  \n",
       "28  1.0    0.0    1.0           0.0  1.682542e+09              clarielz  \n",
       "29  1.0    0.0    1.0           0.0  1.682547e+09               tvgrlds  \n",
       "30  1.0    0.0    1.0           0.0  1.682555e+09    Kooky_Assistant112  \n",
       "31  1.0    0.0    1.0           0.0  1.682558e+09          takeaway_272  \n",
       "32  1.0    0.0    1.0           0.0  1.682587e+09             [deleted]  \n",
       "33  1.0    0.0    1.0           0.0  1.682619e+09               Sunapr1  \n",
       "34  1.0    0.0    1.0           0.0  1.682700e+09             [deleted]  \n",
       "35  1.0    0.0    1.0           0.0  1.682824e+09       sidewayssadface  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'“I’ve already started interviews with another company, but you’re my top choice. Is it possible to wrap up interviews with your company by next week or soon after?”'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reddit_comments.json()[1]['data']['children'][1]['data']['replies']['data']['children'][0]['data']['body']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
